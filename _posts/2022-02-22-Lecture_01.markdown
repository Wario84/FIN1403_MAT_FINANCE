---
layout: post
title: "Introduction to Data Science and Big Data."
author: "Mario H. Gonzalez-Sauri"
date: "2022-02-22"
categories: jekyll update
---

<!--  FORMAT: https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet -->

# Introduction

Data Science, is an emergent discipline that works in the intersection between statistics, mathematics and computer programming. This new discipline is growing faster due to large amounts of data that we are generating, the maturity of information and communication technologies (ICT) and the high availability of powerful computational systems. Data science differs from statistics, the former justifies the development of algorithms to increase our inferential capabilities. That is, algorithms are needed to estimate certain parameter in a statistical or mathematical model, aiming only to claim a 'causal-effect'. However, the later, justifies the development of algorithms not necessarily for inference but for prediction and complex problem solving [@2021Efron10.1017/9781108914062]. For instance, Data Science and Machine Learning (ML) are growing rapidly in intersection with econometrics [@2019Athey10.1146/annureveconomics080217053433]. Broadly speaking, Data Science and ML uses algorithms and powerful numerical methods to solve problems and train computer in an heuristic manner. An heuristic approach means, that the process of problem solving does not rely only on mathematical induction with a neat [`closed-form'](https://stats.stackexchange.com/questions/70848/what-does-a-closed-form-solution-mean) solution, common in optimization, but also from approximations. This approximations are sometimes better and more cost-efficient given the large amount of data.

# The landscape of Data Science in Economics.

To understand better the scope of Data Science and ML this section presents an overview of the **High Impact Factor** peer-review publications in the field of economics. First, we explore the top 10 publications within the field that have had the highest reach among top-researchers using Data Science. What we can observe is the high overlap, between common empirical disciplines like economics but also a connection to finance, market analysis, and policy making. 

## Top 10 Publications in High Impact Journals.

| Rank | Publication | Journal | Year |
| :---         |     :---:      | :---:|:---|
| 1    | [Big Data: New Tricks for Econometrics](https://www-webofscience-com.mu.idm.oclc.org/wos/woscc/full-record/WOS:000344365500001)             | JOURNAL OF ECONOMIC PERSPECTIVES         |   2014   |
| 2    | [Machine Learning: An Applied Econometric Approach](/wos/woscc/full-record/WOS:000403753100004)             | JOURNAL OF ECONOMIC PERSPECTIVES         | 2017      |
| 3    | [The 'actually existing smart city'](/wos/woscc/full-record/WOS:000351054700003)             | CAMBRIDGE JOURNAL OF REGIONS ECONOMY AND SOCIETY        | 2015      |
| 4    | [The State of Applied Econometrics: Causality and Policy Evaluation](/wos/woscc/full-record/WOS:000403753100001) | JOURNAL OF ECONOMIC PERSPECTIVES    | 2017      |
| 5    | [The forthcoming Artificial Intelligence (AI) revolution: Its impact on society and firms](/wos/woscc/full-record/WOS:000403744000004) | ECONOMETRICS JOURNAL | 2018      |
| 6    | [How effective are neural networks at forecasting and prediction? A review and evaluation](/wos/woscc/full-record/WOS:000077416900010) | JOURNAL OF FORECASTING | 2010  |
| 7    | [How effective are neural networks at forecasting and prediction? A review and evaluation](/wos/woscc/full-record/WOS:000077416900010) | ECONOMETRICS REVIEW | 1998     |
| 8    | [An Empirical Comparison of Machine Learning Models for Time Series Forecasting](wos/woscc/full-record/WOS:000281853600006)| JOUNRAL OF BANKING AND FINANC         | 2010      |
| 9    | [Consumer credit-risk models via >machine-learning algorithms](/wos/woscc/full-record/WOS:000281986300016)| JOUNRAL OF BANKING AND FINANC         | 2010      |
| 10   | [Seeing like a market](/wos/woscc/full-record/WOS:000399771000002)            | SOCIO-ECONOMIC REVIEW         | 2017     |

<!-- https://www.markdownguide.org/extended-syntax/ -->
*Source: Web of Science, 2022*



Indeed, the histogram of publications from the field of Data Science shows that in the last years more economists are adopting these empirical set of skills. What is clear as well, is that the pattern seems to be exponential, with a clear increase in the trend between the years of 2014-2015.


<center>
![Web of Science Data Science Publications](/assets/images/woc_dataS_ML_rise.png)
</center>

But what about the sub-disciplines in the field of economics working with Data Science? The top 10 publications show that the field is growing faster in the intersection between empirical economics, finance and policy analysis. The following picture, looks at what are the top sub-disciplines within the field of economics working with data science. What the data is showing is that also fields like management, health economics and operations research are incorporating the use of Data Science for their research.




![try1](/assets/images/woc_dataS_ML_disc.png)

![try2](./assets/images/woc_dataS_ML_disc.png)

<img src="/assets/images/woc_dataS_ML_disc.png" alt="">


<!-- ![[try4]({{ site.base_url }}{% link /assets/imgs/woc_dataS_ML_disc.png %})  -->






# The rise of Big Data

In the last decade, we have seem an increase in the number of publications using Data Science in economics. But this is not only given by the growth of the field itself but also due to the large collection of data. In 2014, it was calculated that there are over 2 billion people worldwide are connected to the Internet, 5 billion individuals with mobile phones, but by 2020, it was predicted an increase of 44%, that is 50 billion of devices with access to internet. This example is just from the telecommunication sector, but image how much data we are generating globally in the financial, eCommerce, transportation or health care sectors. 


I is difficult to define what Big Data really is, it seem, somehow to be an "vague-term" that refers to just a large collection of data. Big data, is more a term "used to describe a wide range of concepts: from the technological ability to store, aggregate, and process data, to the cultural shift that is pervasively invading business and society, both drowning in information overload" [@2015DeMauro10.1063/1.4907823]. Their review provides an excellent group of definitions from different authors, that can guide our understanding of what the term encompasses:

## Towards a Definition of Big Data

|    | Definitions of Big Data   |
|:--|:---:|
| 1  | High volume, velocity and variety information assets that demand   cost-effective, innovative forms of information processing for enhanced   insight and decision making.     |
| 2  | The four characteristics defining big data are Volume, Velocity, Variety and Value.         |
| 3  | Complex, unstructured, or large amounts of data.											   |
| 4  | Can be defined using three data characteristics: Cardinality, Continuity and Complexity.	   |
| 5  | Big data is a combination of Volume, Variety, Velocity and Veracity that creates an opportunity for organizations to gain competitive advantage in todayâ€™s digitized marketplace. |
| 6  | Extensive datasets, primarily in the characteristics of volume, velocity and/or variety, that require a scalable architecture for efficient storage, manipulation, and analysis. |
| 7  | The storage and analysis of large and or complex data sets using a series of techniques including, but not limited to: NoSQL, MapReduce and machine learning. |
| 8  | The process of applying serious computing power, the latest in machine learning and artificial intelligence, to seriously massive and often highly complex sets of information. |
| 9  | Data that exceeds the processing capacity of conventional database systems.         |
| 10 | Data that cannot be handled and processed in a straightforward manner.              |
| 11 | A dataset that is too big to fit on a screen.									   |
| 12 | Datasets whose size is beyond the ability of typical database software tools to capture, store, manage, and analyze. |
| 13 | The data sets and analytical techniques in applications that are so large and complex that they require advanced and unique data storage, management,   analysis, and visualization technologies. |
| 14 | A cultural, technological, and scholarly phenomenon that rests on the interplay of Technology, Analysis and Mythology. |
| 15 | Phenomenon that brings three key shifts in the way we analyze information that transform how we understand and organize society: 1. More data, 2.   Messier (incomplete) data, 3. Correlation overtakes causality. |
| 16 | Big Data represents the Information assets characterized by such a High Volume, Velocity and Variety to require specific Technology and Analytical   Methods for its transformation into Value. |

**Source: [De Mauro, Andrea and Greco, Et. all, 2015](https://aip-scitation-org.mu.idm.oclc.org/doi/abs/10.1063/1.4907823)**

Indeed, the last definition, 16, provided by De Mauro, Andrea and Greco, Et. all (2015), highlights the "raw-value" of Big Data. Namely, Big Data itself is of no use without a specific set of skills, the skills of *Data Scientist*. Big data, implies large volume of data, but this is not necessary clean and neat as typical [relation database](https://en.wikipedia.org/wiki/Relational_database) used by companies and government. 



## Properties of Big Data

In this section, I try to identify some properties of Big Data, that I have reflected upon my observation and practice.

- *Cost-effective*: In the past, empirical studies use to work with large teams for data collection to implement surveys or deploy field experiments. However, today, Data Scientist with [Web Scrapping](https://www.tandfonline.com/doi/pdf/10.1080/10691898.2020.1787116) skills, can collect with a single computer millions of observations. 

- *Dimension*: A feature of big data is that different from survey data, that only contains a lesser number of variables. Big data typically contain multiple dimensions of variables on the same unit of observation. 

- *Scope*: Another element of Big Data is that not it is able to merge multiple layers of units. That means that Big data is often able to map observations from micro units that is merge with higher order units. You can think of users of cellphones from a district, that are merge with data from their state and even their country. Some authors refers to this as the *granularity* of the data.

- *Unstructured*:  However, with the advent of Data Science and ML, more and more scientist are harvesting data available from different databases and websites. This data however, is unstructured and fuzzy, deviates from neat relational databases and requires special Data Science skills to harvest the value out of it. 


![a gif!](https://media.giphy.com/media/l0MYt5jPR6QX5pnqM/giphy.gif)